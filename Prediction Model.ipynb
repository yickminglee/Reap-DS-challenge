{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "# Basic\n",
    "from time import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Viz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Objective:\n",
    "\n",
    "- Train a model to predict whether a user will default or not\n",
    "- Evaluate the performance of model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# My plan\n",
    "\n",
    "1. Model the 6 selected features on a few other models and tune hyper parameters\n",
    "2. Select the best model.\n",
    "3. Tune probability threshold to improve accuracy\n",
    "4. Show model performance with k fold cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Load model and set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_pickle(\"df_trans.pkl\")\n",
    "feature_names = ['N_PAY_DULY', 'N_DELAYED', 'UTILIZE_PTG1', 'PAY_PTG1', 'PAY_1_delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data\n",
    "df_train,df_test = train_test_split(df_trans,test_size=0.2,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEFAULT_PAY</th>\n",
       "      <th>N_USERS</th>\n",
       "      <th>PTG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6211</td>\n",
       "      <td>0.776375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1789</td>\n",
       "      <td>0.223625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEFAULT_PAY  N_USERS       PTG\n",
       "0            0     6211  0.776375\n",
       "1            1     1789  0.223625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training data\n",
    "d_rate = df_train.groupby(['DEFAULT_PAY']).size().reset_index(name='N_USERS')\n",
    "d_rate['PTG'] = d_rate['N_USERS']/sum(d_rate['N_USERS'])\n",
    "d_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DEFAULT_PAY</th>\n",
       "      <th>N_USERS</th>\n",
       "      <th>PTG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1551</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>0.2245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DEFAULT_PAY  N_USERS     PTG\n",
       "0            0     1551  0.7755\n",
       "1            1      449  0.2245"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check testing data\n",
    "d_rate = df_test.groupby(['DEFAULT_PAY']).size().reset_index(name='N_USERS')\n",
    "d_rate['PTG'] = d_rate['N_USERS']/sum(d_rate['N_USERS'])\n",
    "d_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 training score: 0.4904480722473081\n",
      "F1 testing score: 0.4524137931034483\n",
      "Training time: 0.176 s\n",
      "Prediction time: 0.001 s\n",
      "Accuracy training score: 0.816625\n",
      "Accuracy testing score: 0.8015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# get feature and labels\n",
    "features_train, features_test = \\\n",
    "    df_train[feature_names].values, df_test[feature_names].values\n",
    "labels_train, labels_test = \\\n",
    "    df_train['DEFAULT_PAY'].values,df_test['DEFAULT_PAY'].values\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=35, \n",
    "                                 max_depth = 3, \n",
    "                                 min_samples_split = 100, \n",
    "                                 min_samples_leaf = 50,\n",
    "                                 #max_features=10,\n",
    "                                 random_state = 0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "training_time = round(time() - t0, 3)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "t0 = time()\n",
    "predictions = clf.predict(features_test)\n",
    "prediction_time = round(time() - t0, 3)\n",
    "\n",
    "# evaluate result\n",
    "training_score = f1_score(y_true = labels_train, y_pred = clf.predict(features_train))\n",
    "score = f1_score(y_true = labels_test, y_pred = predictions)\n",
    "\n",
    "# Print results\n",
    "print (\"F1 training score:\", training_score)\n",
    "print (\"F1 testing score:\", score)\n",
    "print (\"Training time:\", training_time, \"s\")\n",
    "print (\"Prediction time:\", prediction_time, \"s\")\n",
    "\n",
    "# quickly check the accuracy score as well\n",
    "print (\"Accuracy training score:\", metrics.accuracy_score(labels_train, clf.predict(features_train)))\n",
    "print (\"Accuracy testing score:\", metrics.accuracy_score(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Try a few more models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.5 s, sys: 92 ms, total: 25.6 s\n",
      "Wall time: 25.6 s\n",
      "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.075, loss='deviance', max_depth=3,\n",
      "                           max_features='log2', max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=50, min_samples_split=100,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=35,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "0.47640251636018816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"min_samples_split\": [100],\n",
    "    \"min_samples_leaf\": [50],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"n_estimators\":[35]\n",
    "    }\n",
    "\n",
    "acc_scorer = make_scorer(f1_score)\n",
    "grid_clf = GridSearchCV(GradientBoostingClassifier(), param_grid, scoring = acc_scorer, cv=5)\n",
    "%time grid_clf = grid_clf.fit(features_train, labels_train)\n",
    "best_clf = grid_clf.best_estimator_\n",
    "print(grid_clf.best_estimator_)\n",
    "print(grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 training score: 0.48299791811242193\n",
      "F1 testing score: 0.45604395604395603\n",
      "Training time: 0.106 s\n",
      "Prediction time: 0.001 s\n",
      "Accuracy training score: 0.81375\n",
      "Accuracy testing score: 0.802\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# get feature and labels\n",
    "features_train, features_test = \\\n",
    "    df_train[feature_names].values, df_test[feature_names].values\n",
    "labels_train, labels_test = \\\n",
    "    df_train['DEFAULT_PAY'].values,df_test['DEFAULT_PAY'].values\n",
    "\n",
    "clf = best_clf\n",
    "\n",
    "# Train the model using the training sets\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "training_time = round(time() - t0, 3)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "t0 = time()\n",
    "predictions = clf.predict(features_test)\n",
    "prediction_time = round(time() - t0, 3)\n",
    "\n",
    "# evaluate result\n",
    "training_score = f1_score(y_true = labels_train, y_pred = clf.predict(features_train))\n",
    "score = f1_score(y_true = labels_test, y_pred = predictions)\n",
    "\n",
    "# Print results\n",
    "print (\"F1 training score:\", training_score)\n",
    "print (\"F1 testing score:\", score)\n",
    "print (\"Training time:\", training_time, \"s\")\n",
    "print (\"Prediction time:\", prediction_time, \"s\")\n",
    "\n",
    "# quickly check the accuracy score as well\n",
    "print (\"Accuracy training score:\", metrics.accuracy_score(labels_train, clf.predict(features_train)))\n",
    "print (\"Accuracy testing score:\", metrics.accuracy_score(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100., 110., 120., 130., 140., 150., 160., 170., 180., 190., 200.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(100, 200, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 190 ms, total: 34.7 s\n",
      "Wall time: 34.8 s\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=3, max_features='log2',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=50, min_samples_split=200,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.49663023307403076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"min_samples_split\": [100, 150, 200],\n",
    "    \"min_samples_leaf\": [50],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"n_estimators\":[35,100]\n",
    "    }\n",
    "\n",
    "acc_scorer = make_scorer(f1_score)\n",
    "grid_clf = GridSearchCV(RandomForestClassifier(), param_grid, scoring = acc_scorer, cv=5)\n",
    "%time grid_clf = grid_clf.fit(features_train, labels_train)\n",
    "best_clf = grid_clf.best_estimator_\n",
    "print(grid_clf.best_estimator_)\n",
    "print(grid_clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 training score: 0.4966532797858099\n",
      "F1 testing score: 0.46586345381526106\n",
      "Training time: 0.104 s\n",
      "Prediction time: 0.006 s\n",
      "Accuracy training score: 0.812\n",
      "Accuracy testing score: 0.8005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# get feature and labels\n",
    "features_train, features_test = \\\n",
    "    df_train[feature_names].values, df_test[feature_names].values\n",
    "labels_train, labels_test = \\\n",
    "    df_train['DEFAULT_PAY'].values,df_test['DEFAULT_PAY'].values\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=35, \n",
    "                                 max_depth = 3, \n",
    "                                 min_samples_split = 100, \n",
    "                                 min_samples_leaf = 50,\n",
    "                                 max_features='log2',\n",
    "                                 random_state = 0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "training_time = round(time() - t0, 3)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "t0 = time()\n",
    "predictions = clf.predict(features_test)\n",
    "prediction_time = round(time() - t0, 3)\n",
    "\n",
    "# evaluate result\n",
    "training_score = f1_score(y_true = labels_train, y_pred = clf.predict(features_train))\n",
    "score = f1_score(y_true = labels_test, y_pred = predictions)\n",
    "\n",
    "# Print results\n",
    "print (\"F1 training score:\", training_score)\n",
    "print (\"F1 testing score:\", score)\n",
    "print (\"Training time:\", training_time, \"s\")\n",
    "print (\"Prediction time:\", prediction_time, \"s\")\n",
    "\n",
    "# quickly check the accuracy score as well\n",
    "print (\"Accuracy training score:\", metrics.accuracy_score(labels_train, clf.predict(features_train)))\n",
    "print (\"Accuracy testing score:\", metrics.accuracy_score(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2.3. XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/yickminglee/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yickminglee/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-42076764cb80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# get feature and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;34m'`brew install libomp` to install OpenMP runtime.\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;34m'  * You are running 32-bit Python on a 64-bit OS\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             'Error message(s): {}\\n'.format(os_error_list))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/Users/yickminglee/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yickminglee/.virtualenvs/ming-ds/lib/python3.6/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# get feature and labels\n",
    "features_train, features_test = \\\n",
    "    df_train[feature_names].values, df_test[feature_names].values\n",
    "labels_train, labels_test = \\\n",
    "    df_train['DEFAULT_PAY'].values,df_test['DEFAULT_PAY'].values\n",
    "\n",
    "clf = XGBClassifier(learning_rate = 0.05, n_estimators=300, max_depth=5)\n",
    "\n",
    "# Train the model using the training sets\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "training_time = round(time() - t0, 3)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "t0 = time()\n",
    "predictions = clf.predict(features_test)\n",
    "prediction_time = round(time() - t0, 3)\n",
    "\n",
    "# evaluate result\n",
    "training_score = f1_score(y_true = labels_train, y_pred = clf.predict(features_train))\n",
    "score = f1_score(y_true = labels_test, y_pred = predictions)\n",
    "\n",
    "# Print results\n",
    "print (\"F1 training score:\", training_score)\n",
    "print (\"F1 testing score:\", score)\n",
    "print (\"Training time:\", training_time, \"s\")\n",
    "print (\"Prediction time:\", prediction_time, \"s\")\n",
    "\n",
    "# quickly check the accuracy score as well\n",
    "print (\"Accuracy training score:\", metrics.accuracy_score(labels_train, clf.predict(features_train)))\n",
    "print (\"Accuracy testing score:\", metrics.accuracy_score(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Try tuning threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf_prob = clf.predict_proba(features_test)[:,1]\n",
    "\n",
    "df_test_result = pd.DataFrame({'actual_values':labels_test, 'prediction': pd.Series(clf_prob),'prediction-yn': predictions})\n",
    "\n",
    "df_test_result.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Compute Classifier's Accuracy for various thresholds \n",
    "\n",
    "def _compute_accuracy_for_thresholds(data: pd.core.frame.DataFrame):\n",
    "\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    accuracies = []\n",
    "    for threshold in thresholds:\n",
    "        preds = df_test_result['prediction'].map(lambda x: 1 if x > threshold else 0)\n",
    "        accuracy_ = metrics.accuracy_score(df_test_result['actual_values'].values, preds)\n",
    "        accuracies.append(accuracy_)\n",
    "    return accuracies, thresholds\n",
    "\n",
    "accuracies, threshold = _compute_accuracy_for_thresholds(df_test_result)\n",
    "\n",
    "max_value = np.amax(accuracies)\n",
    "max_position = np.where(accuracies == max_value)\n",
    "print(\"maximum accuracies: {}; maximum threshold: {}\".format(max_value, threshold[max_position]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "ax = sns.lineplot(x=threshold, y=accuracies,\n",
    "                  markers=True, dashes=False)\n",
    "\n",
    "axes = ax.axes\n",
    "axes.set_ylim(0.7,0.85)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest point is around 0.5, not too far off from the default setting. So, I am not going to make any changes here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Show model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
